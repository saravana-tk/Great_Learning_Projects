{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zUZjPnVXGz0Z"
   },
   "source": [
    "# The Iris Dataset\n",
    "The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimeters.\n",
    "\n",
    "The dataset contains a set of 150 records under five attributes - petal length, petal width, sepal length, sepal width and species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMbmpriavLE9"
   },
   "source": [
    "### Specifying the TensorFlow version\n",
    "Running `import tensorflow` will import the default version (currently 1.x). You can use 2.x by running a cell with the `tensorflow_version` magic **before** you run `import tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fu8bUU__oa7h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bLz1Ckvfvn6D"
   },
   "source": [
    "### Import TensorFlow\n",
    "Once you have specified a version via this magic, you can run `import tensorflow` as normal and verify which version was imported as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CWrzVTLOvn6M"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_uYeJgkNuXNC"
   },
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lcASNsewsfQX"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5-vVQBBqg7DI"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kE0EDKvQhEIe"
   },
   "source": [
    "### Import dataset\n",
    "- Import iris dataset\n",
    "- Import the dataset using sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOOWpD26Haq3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ta8YqInTh5v5"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HERt3drbhX0i"
   },
   "source": [
    "### Get features and label from the dataset in separate variable\n",
    "- you can get the features using .data method\n",
    "- you can get the features using .target method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0cV-_qHAHyvE"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "..      ...  \n",
       "145     2.0  \n",
       "146     2.0  \n",
       "147     2.0  \n",
       "148     2.0  \n",
       "149     2.0  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qg1A2lkUjFak"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3YErwYLCH0N_"
   },
   "source": [
    "### Create train and test data\n",
    "- use train_test_split to get train and test set\n",
    "- set a random_state\n",
    "- test_size: 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYKNJL85h7pQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SaravanaTK/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"\n",
      "/Users/SaravanaTK/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Import `train_test_split` from `sklearn.model_selection`\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Specify the data \n",
    "X=df.ix[:,0:4]\n",
    "\n",
    "# Specify the target labels and flatten the array\n",
    "y= df.ix[:,4]\n",
    "#y= wines.type\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92     1.0\n",
       "44     0.0\n",
       "7      0.0\n",
       "21     0.0\n",
       "95     1.0\n",
       "75     1.0\n",
       "20     0.0\n",
       "121    2.0\n",
       "26     0.0\n",
       "19     0.0\n",
       "81     1.0\n",
       "88     1.0\n",
       "143    2.0\n",
       "117    2.0\n",
       "23     0.0\n",
       "77     1.0\n",
       "138    2.0\n",
       "73     1.0\n",
       "14     0.0\n",
       "142    2.0\n",
       "123    2.0\n",
       "62     1.0\n",
       "83     1.0\n",
       "74     1.0\n",
       "42     0.0\n",
       "60     1.0\n",
       "40     0.0\n",
       "45     0.0\n",
       "87     1.0\n",
       "124    2.0\n",
       "41     0.0\n",
       "131    2.0\n",
       "70     1.0\n",
       "46     0.0\n",
       "126    2.0\n",
       "54     1.0\n",
       "85     1.0\n",
       "114    2.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g0KVP17Ozaix"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SIjqxbhWv1zv"
   },
   "source": [
    "### One-hot encode the labels\n",
    "- convert class vectors (integers) to binary class matrix\n",
    "- convert labels\n",
    "- number of classes: 3\n",
    "- we are doing this to use categorical_crossentropy as loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R9vv-_gpyLY9"
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 3)\n",
    "y_test = keras.utils.to_categorical(y_test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ovjLyYzWkO9s"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hbIFzoPNSyYo"
   },
   "source": [
    "### Initialize a sequential model\n",
    "- Define a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4FvSbf1UjHtl"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# Initialize the constructor\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dGMy999vlacX"
   },
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "72ibK5Jxm8iL"
   },
   "source": [
    "### Add a layer\n",
    "- Use Dense Layer  with input shape of 4 (according to the feature set) and number of outputs set to 3\n",
    "- Apply Softmax on Dense Layer outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uZKrBNSRm_o9"
   },
   "outputs": [],
   "source": [
    "# Define model architecture\n",
    "\n",
    "model.add(Dense(3, activation='softmax', input_shape=(4,)))\n",
    "#model.add(Dense(3,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i4uiTH8plmNX"
   },
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJL8n8vcSyYz"
   },
   "source": [
    "### Compile the model\n",
    "- Use SGD as Optimizer\n",
    "- Use categorical_crossentropy as loss function\n",
    "- Use accuracy as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tc_-fjIEk1ve"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sihIGbRll_jT"
   },
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54ZZCfNGlu0i"
   },
   "source": [
    "### Summarize the model\n",
    "- Check model layers\n",
    "- Understand number of trainable parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "elER3F_4ln8n"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_14 (Dense)             (None, 3)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2PiP7j3Vmj4p"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rWdbfFCXmCHt"
   },
   "source": [
    "### Fit the model\n",
    "- Give train data as training features and labels\n",
    "- Epochs: 100\n",
    "- Give validation data as testing features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cO1c-5tjmBVZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n",
      "Train on 112 samples\n",
      "Epoch 1/100\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 1.1849 - accuracy: 0.4196\n",
      "Epoch 2/100\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.7026 - accuracy: 0.6964\n",
      "Epoch 3/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.6008 - accuracy: 0.7054\n",
      "Epoch 4/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.5066 - accuracy: 0.7589\n",
      "Epoch 5/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.4989 - accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.4684 - accuracy: 0.7857\n",
      "Epoch 7/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.4432 - accuracy: 0.8125\n",
      "Epoch 8/100\n",
      "112/112 [==============================] - 1s 5ms/sample - loss: 0.4168 - accuracy: 0.8036\n",
      "Epoch 9/100\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.4060 - accuracy: 0.8393\n",
      "Epoch 10/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.3510 - accuracy: 0.8750\n",
      "Epoch 11/100\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.3459 - accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.3439 - accuracy: 0.8929\n",
      "Epoch 13/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.3414 - accuracy: 0.8929\n",
      "Epoch 14/100\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.3277 - accuracy: 0.90 - 0s 4ms/sample - loss: 0.3340 - accuracy: 0.8929\n",
      "Epoch 15/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.3022 - accuracy: 0.9196\n",
      "Epoch 16/100\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.3018 - accuracy: 0.9018\n",
      "Epoch 17/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.2800 - accuracy: 0.9196\n",
      "Epoch 18/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.2657 - accuracy: 0.9196\n",
      "Epoch 19/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2726 - accuracy: 0.9286\n",
      "Epoch 20/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2697 - accuracy: 0.9286\n",
      "Epoch 21/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2559 - accuracy: 0.9286\n",
      "Epoch 22/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2457 - accuracy: 0.9196\n",
      "Epoch 23/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2501 - accuracy: 0.9554\n",
      "Epoch 24/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2351 - accuracy: 0.9375\n",
      "Epoch 25/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2322 - accuracy: 0.9554\n",
      "Epoch 26/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2293 - accuracy: 0.9464\n",
      "Epoch 27/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2261 - accuracy: 0.9464\n",
      "Epoch 28/100\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.2267 - accuracy: 0.9554\n",
      "Epoch 29/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.2182 - accuracy: 0.9375\n",
      "Epoch 30/100\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.2104 - accuracy: 0.9732\n",
      "Epoch 31/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.2050 - accuracy: 0.9464\n",
      "Epoch 32/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1949 - accuracy: 0.9643\n",
      "Epoch 33/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1883 - accuracy: 0.9643\n",
      "Epoch 34/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1995 - accuracy: 0.9554\n",
      "Epoch 35/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1912 - accuracy: 0.9464\n",
      "Epoch 36/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1842 - accuracy: 0.9643\n",
      "Epoch 37/100\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.1846 - accuracy: 0.9732\n",
      "Epoch 38/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1836 - accuracy: 0.9464\n",
      "Epoch 39/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1882 - accuracy: 0.9464\n",
      "Epoch 40/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1758 - accuracy: 0.9911\n",
      "Epoch 41/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1812 - accuracy: 0.9554\n",
      "Epoch 42/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1731 - accuracy: 0.9554\n",
      "Epoch 43/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1696 - accuracy: 0.9554\n",
      "Epoch 44/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1713 - accuracy: 0.9643\n",
      "Epoch 45/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1702 - accuracy: 0.9911\n",
      "Epoch 46/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1679 - accuracy: 0.9732\n",
      "Epoch 47/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1681 - accuracy: 0.9643\n",
      "Epoch 48/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1607 - accuracy: 0.9554\n",
      "Epoch 49/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1585 - accuracy: 0.9554\n",
      "Epoch 50/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1557 - accuracy: 0.9732\n",
      "Epoch 51/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1620 - accuracy: 0.9821\n",
      "Epoch 52/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1507 - accuracy: 0.9643\n",
      "Epoch 53/100\n",
      "112/112 [==============================] - 0s 1ms/sample - loss: 0.1483 - accuracy: 0.9732\n",
      "Epoch 54/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1501 - accuracy: 0.9911\n",
      "Epoch 55/100\n",
      "112/112 [==============================] - 0s 1ms/sample - loss: 0.1421 - accuracy: 0.9732\n",
      "Epoch 56/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1525 - accuracy: 0.9732\n",
      "Epoch 57/100\n",
      "112/112 [==============================] - 0s 1ms/sample - loss: 0.1454 - accuracy: 0.9643\n",
      "Epoch 58/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1402 - accuracy: 0.9821\n",
      "Epoch 59/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1404 - accuracy: 0.9643\n",
      "Epoch 60/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1368 - accuracy: 0.9821\n",
      "Epoch 61/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1440 - accuracy: 0.9821\n",
      "Epoch 62/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1410 - accuracy: 0.9554\n",
      "Epoch 63/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1356 - accuracy: 0.9732\n",
      "Epoch 64/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1386 - accuracy: 0.9821\n",
      "Epoch 65/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1387 - accuracy: 0.9821\n",
      "Epoch 66/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1339 - accuracy: 0.9732\n",
      "Epoch 67/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1330 - accuracy: 0.9821\n",
      "Epoch 68/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1374 - accuracy: 0.9554\n",
      "Epoch 69/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1306 - accuracy: 0.9821\n",
      "Epoch 70/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1229 - accuracy: 0.9732\n",
      "Epoch 71/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1237 - accuracy: 0.9911\n",
      "Epoch 72/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1253 - accuracy: 0.9643\n",
      "Epoch 73/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1318 - accuracy: 0.9911\n",
      "Epoch 74/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1228 - accuracy: 0.9911\n",
      "Epoch 75/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1281 - accuracy: 0.9643\n",
      "Epoch 76/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1249 - accuracy: 0.9821\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1230 - accuracy: 0.9821\n",
      "Epoch 78/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1171 - accuracy: 0.9911\n",
      "Epoch 79/100\n",
      "112/112 [==============================] - 0s 4ms/sample - loss: 0.1214 - accuracy: 0.9821\n",
      "Epoch 80/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1212 - accuracy: 0.9732\n",
      "Epoch 81/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1251 - accuracy: 0.9732\n",
      "Epoch 82/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1219 - accuracy: 0.9554\n",
      "Epoch 83/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1194 - accuracy: 0.9732\n",
      "Epoch 84/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1223 - accuracy: 0.9732\n",
      "Epoch 85/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1212 - accuracy: 0.9911\n",
      "Epoch 86/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1106 - accuracy: 0.9821\n",
      "Epoch 87/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1175 - accuracy: 0.9643\n",
      "Epoch 88/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1168 - accuracy: 0.9732\n",
      "Epoch 89/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1142 - accuracy: 0.9732\n",
      "Epoch 90/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1167 - accuracy: 0.9554\n",
      "Epoch 91/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1116 - accuracy: 0.9821\n",
      "Epoch 92/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1142 - accuracy: 0.9464\n",
      "Epoch 93/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1120 - accuracy: 0.9732\n",
      "Epoch 94/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.0996 - accuracy: 0.9821\n",
      "Epoch 95/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1163 - accuracy: 0.9554\n",
      "Epoch 96/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1144 - accuracy: 0.9732\n",
      "Epoch 97/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1019 - accuracy: 0.9911\n",
      "Epoch 98/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1038 - accuracy: 0.9732\n",
      "Epoch 99/100\n",
      "112/112 [==============================] - 0s 2ms/sample - loss: 0.1075 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "112/112 [==============================] - 0s 3ms/sample - loss: 0.1067 - accuracy: 0.9732\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,epochs=100, batch_size=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "re9ItAR3yS3J"
   },
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "liw0IFf9yVqH"
   },
   "source": [
    "### Make predictions\n",
    "- Predict labels on one row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H5sBybi6mlLl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n",
    "y_pred = np.round(model.predict(X_test))\n",
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hSUgMq3m0bG7"
   },
   "source": [
    "### Compare the prediction with actual label\n",
    "- Print the same row as done in the previous step but of actual labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K5WbwVPyz-qQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FrTKwbgE7NFT"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a1UBYPNp5Tn1"
   },
   "source": [
    "# Stock prices dataset\n",
    "The data is of tock exchange's stock listings for each trading day of 2010 to 2016.\n",
    "\n",
    "## Description\n",
    "A brief description of columns.\n",
    "- open: The opening market price of the equity symbol on the date\n",
    "- high: The highest market price of the equity symbol on the date\n",
    "- low: The lowest recorded market price of the equity symbol on the date\n",
    "- close: The closing recorded price of the equity symbol on the date\n",
    "- symbol: Symbol of the listed company\n",
    "- volume: Total traded volume of the equity symbol on the date\n",
    "- date: Date of record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ctH_ZW5g-M3g"
   },
   "source": [
    "### Specifying the TensorFlow version\n",
    "Running `import tensorflow` will import the default version (currently 1.x). You can use 2.x by running a cell with the `tensorflow_version` magic **before** you run `import tensorflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQbdODpH-M3r"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorflow_version` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nFQWH1tj-M38"
   },
   "source": [
    "### Import TensorFlow\n",
    "Once you have specified a version via this magic, you can run `import tensorflow` as normal and verify which version was imported as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ho5n-xhd-M3_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tgkl0qu6-M4F"
   },
   "source": [
    "### Set random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKgTyuA3-M4G"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_88voqAH-O6J"
   },
   "source": [
    "## Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRHCeJqP-evf"
   },
   "source": [
    "### Load the data\n",
    "- load the csv file and read it using pandas\n",
    "- file name is prices.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKVH5v7r-RmC"
   },
   "outputs": [],
   "source": [
    "# run this cell to upload file if you are using google colab\n",
    "#from google.colab import files\n",
    "#files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-gDC6cSW_FSK"
   },
   "outputs": [],
   "source": [
    "df_prices = pd.read_csv('prices.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>symbol</th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-05 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2016-01-07 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2016-01-08 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2016-01-11 00:00:00</td>\n",
       "      <td>WLTW</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851259</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>ZBH</td>\n",
       "      <td>103.309998</td>\n",
       "      <td>103.199997</td>\n",
       "      <td>102.849998</td>\n",
       "      <td>103.930000</td>\n",
       "      <td>973800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851260</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>ZION</td>\n",
       "      <td>43.070000</td>\n",
       "      <td>43.040001</td>\n",
       "      <td>42.689999</td>\n",
       "      <td>43.310001</td>\n",
       "      <td>1938100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851261</td>\n",
       "      <td>2016-12-30</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>53.639999</td>\n",
       "      <td>53.529999</td>\n",
       "      <td>53.270000</td>\n",
       "      <td>53.740002</td>\n",
       "      <td>1701200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851262</td>\n",
       "      <td>2016-12-30 00:00:00</td>\n",
       "      <td>AIV</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>45.450001</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>45.590000</td>\n",
       "      <td>1380900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851263</td>\n",
       "      <td>2016-12-30 00:00:00</td>\n",
       "      <td>FTV</td>\n",
       "      <td>54.200001</td>\n",
       "      <td>53.630001</td>\n",
       "      <td>53.389999</td>\n",
       "      <td>54.480000</td>\n",
       "      <td>705100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>851264 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date symbol        open       close         low  \\\n",
       "0       2016-01-05 00:00:00   WLTW  123.430000  125.839996  122.309998   \n",
       "1       2016-01-06 00:00:00   WLTW  125.239998  119.980003  119.940002   \n",
       "2       2016-01-07 00:00:00   WLTW  116.379997  114.949997  114.930000   \n",
       "3       2016-01-08 00:00:00   WLTW  115.480003  116.620003  113.500000   \n",
       "4       2016-01-11 00:00:00   WLTW  117.010002  114.970001  114.089996   \n",
       "...                     ...    ...         ...         ...         ...   \n",
       "851259           2016-12-30    ZBH  103.309998  103.199997  102.849998   \n",
       "851260           2016-12-30   ZION   43.070000   43.040001   42.689999   \n",
       "851261           2016-12-30    ZTS   53.639999   53.529999   53.270000   \n",
       "851262  2016-12-30 00:00:00    AIV   44.730000   45.450001   44.410000   \n",
       "851263  2016-12-30 00:00:00    FTV   54.200001   53.630001   53.389999   \n",
       "\n",
       "              high     volume  \n",
       "0       126.250000  2163600.0  \n",
       "1       125.540001  2386400.0  \n",
       "2       119.739998  2489500.0  \n",
       "3       117.440002  2006300.0  \n",
       "4       117.330002  1408600.0  \n",
       "...            ...        ...  \n",
       "851259  103.930000   973800.0  \n",
       "851260   43.310001  1938100.0  \n",
       "851261   53.740002  1701200.0  \n",
       "851262   45.590000  1380900.0  \n",
       "851263   54.480000   705100.0  \n",
       "\n",
       "[851264 rows x 7 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlLKVPVH_BCT"
   },
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9J4BlzVA_gZd"
   },
   "source": [
    "### Drop columnns\n",
    "- drop \"date\" and \"symbol\" column from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IKEK8aEE_Csx"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851259</td>\n",
       "      <td>103.309998</td>\n",
       "      <td>103.199997</td>\n",
       "      <td>102.849998</td>\n",
       "      <td>103.930000</td>\n",
       "      <td>973800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851260</td>\n",
       "      <td>43.070000</td>\n",
       "      <td>43.040001</td>\n",
       "      <td>42.689999</td>\n",
       "      <td>43.310001</td>\n",
       "      <td>1938100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851261</td>\n",
       "      <td>53.639999</td>\n",
       "      <td>53.529999</td>\n",
       "      <td>53.270000</td>\n",
       "      <td>53.740002</td>\n",
       "      <td>1701200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851262</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>45.450001</td>\n",
       "      <td>44.410000</td>\n",
       "      <td>45.590000</td>\n",
       "      <td>1380900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851263</td>\n",
       "      <td>54.200001</td>\n",
       "      <td>53.630001</td>\n",
       "      <td>53.389999</td>\n",
       "      <td>54.480000</td>\n",
       "      <td>705100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>851264 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              open       close         low        high     volume\n",
       "0       123.430000  125.839996  122.309998  126.250000  2163600.0\n",
       "1       125.239998  119.980003  119.940002  125.540001  2386400.0\n",
       "2       116.379997  114.949997  114.930000  119.739998  2489500.0\n",
       "3       115.480003  116.620003  113.500000  117.440002  2006300.0\n",
       "4       117.010002  114.970001  114.089996  117.330002  1408600.0\n",
       "...            ...         ...         ...         ...        ...\n",
       "851259  103.309998  103.199997  102.849998  103.930000   973800.0\n",
       "851260   43.070000   43.040001   42.689999   43.310001  1938100.0\n",
       "851261   53.639999   53.529999   53.270000   53.740002  1701200.0\n",
       "851262   44.730000   45.450001   44.410000   45.590000  1380900.0\n",
       "851263   54.200001   53.630001   53.389999   54.480000   705100.0\n",
       "\n",
       "[851264 rows x 5 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.drop(['date','symbol'], axis=1, inplace = True)\n",
    "df_prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cTPhO6v-AiZt"
   },
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SsZXmF3NAkna"
   },
   "source": [
    "### Take initial rows\n",
    "- Take first 1000 rows from the data\n",
    "- This step is done to make the execution faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aKs04iIHAjxN"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>low</th>\n",
       "      <th>high</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>123.430000</td>\n",
       "      <td>125.839996</td>\n",
       "      <td>122.309998</td>\n",
       "      <td>126.250000</td>\n",
       "      <td>2163600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>125.239998</td>\n",
       "      <td>119.980003</td>\n",
       "      <td>119.940002</td>\n",
       "      <td>125.540001</td>\n",
       "      <td>2386400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>114.949997</td>\n",
       "      <td>114.930000</td>\n",
       "      <td>119.739998</td>\n",
       "      <td>2489500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>115.480003</td>\n",
       "      <td>116.620003</td>\n",
       "      <td>113.500000</td>\n",
       "      <td>117.440002</td>\n",
       "      <td>2006300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>117.010002</td>\n",
       "      <td>114.970001</td>\n",
       "      <td>114.089996</td>\n",
       "      <td>117.330002</td>\n",
       "      <td>1408600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>995</td>\n",
       "      <td>63.310001</td>\n",
       "      <td>63.590000</td>\n",
       "      <td>63.240002</td>\n",
       "      <td>63.639999</td>\n",
       "      <td>2133200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>996</td>\n",
       "      <td>27.160000</td>\n",
       "      <td>26.990000</td>\n",
       "      <td>26.680000</td>\n",
       "      <td>27.299999</td>\n",
       "      <td>1982400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>997</td>\n",
       "      <td>28.320000</td>\n",
       "      <td>28.770000</td>\n",
       "      <td>28.010000</td>\n",
       "      <td>28.809999</td>\n",
       "      <td>37152800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>998</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>44.799999</td>\n",
       "      <td>43.750000</td>\n",
       "      <td>44.810001</td>\n",
       "      <td>6568600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>999</td>\n",
       "      <td>36.080002</td>\n",
       "      <td>37.139999</td>\n",
       "      <td>36.009998</td>\n",
       "      <td>37.230000</td>\n",
       "      <td>5604300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           open       close         low        high      volume\n",
       "0    123.430000  125.839996  122.309998  126.250000   2163600.0\n",
       "1    125.239998  119.980003  119.940002  125.540001   2386400.0\n",
       "2    116.379997  114.949997  114.930000  119.739998   2489500.0\n",
       "3    115.480003  116.620003  113.500000  117.440002   2006300.0\n",
       "4    117.010002  114.970001  114.089996  117.330002   1408600.0\n",
       "..          ...         ...         ...         ...         ...\n",
       "995   63.310001   63.590000   63.240002   63.639999   2133200.0\n",
       "996   27.160000   26.990000   26.680000   27.299999   1982400.0\n",
       "997   28.320000   28.770000   28.010000   28.809999  37152800.0\n",
       "998   44.000000   44.799999   43.750000   44.810001   6568600.0\n",
       "999   36.080002   37.139999   36.009998   37.230000   5604300.0\n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices = df_prices.head(1000)\n",
    "df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 5)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prices.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6vGtnapgBIJm"
   },
   "source": [
    "## Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C8u_jlbABTip"
   },
   "source": [
    "### Get features and label from the dataset in separate variable\n",
    "- Take \"open\", \"close\", \"low\", \"high\" columns as features\n",
    "- Take \"volume\" column as label\n",
    "- Normalize label column by dividing it with 1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQjCMzUXBJbg"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SaravanaTK/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/Users/SaravanaTK/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "X=df_prices.ix[:,0:4]\n",
    "\n",
    "# Specify the target labels and flatten the array\n",
    "y= df_prices.ix[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2154746, shape=(1000, 4), dtype=float32, numpy=\n",
       "array([[0.4958289 , 0.50551003, 0.49132976, 0.5071571 ],\n",
       "       [0.51032925, 0.48889577, 0.48873278, 0.51155174],\n",
       "       [0.49941418, 0.49327773, 0.4931919 , 0.51383275],\n",
       "       ...,\n",
       "       [0.49720097, 0.50510144, 0.49175844, 0.50580364],\n",
       "       [0.4961377 , 0.50515836, 0.49331874, 0.50527114],\n",
       "       [0.49263427, 0.50710744, 0.49167845, 0.50833625]], dtype=float32)>"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y/1000000 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.1636\n",
       "1       2.3864\n",
       "2       2.4895\n",
       "3       2.0063\n",
       "4       1.4086\n",
       "        ...   \n",
       "995     2.1332\n",
       "996     1.9824\n",
       "997    37.1528\n",
       "998     6.5686\n",
       "999     5.6043\n",
       "Name: volume, Length: 1000, dtype: float64"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aTAKzlxZBz0z"
   },
   "source": [
    "## Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IfY8Km1Zzyt2"
   },
   "source": [
    "### Convert data\n",
    "- Convert features and labels to numpy array\n",
    "- Convert their data type to \"float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ko7nnQVbYENh"
   },
   "outputs": [],
   "source": [
    "X = X.to_numpy(dtype = 'float32' )\n",
    "y = y.to_numpy(dtype = 'float32' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3TWpN0nVTpUx"
   },
   "source": [
    "## Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WQ1FKEs-4btX"
   },
   "source": [
    "### Normalize data\n",
    "- Normalize features\n",
    "- Use tf.math.l2_normalize to normalize features\n",
    "- You can read more about it here https://www.tensorflow.org/api_docs/python/tf/math/l2_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0Tfe00X78wB"
   },
   "outputs": [],
   "source": [
    "X = tf.math.l2_normalize(X, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wmXUGc2oTspa"
   },
   "source": [
    "## Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VJelDMpzxs0L"
   },
   "source": [
    "### Define weight and bias\n",
    "- Initialize weight and bias with tf.zeros\n",
    "- tf.zeros is an initializer that generates tensors initialized to 0\n",
    "- Specify the value for shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8o9RPWVTxs0O"
   },
   "outputs": [],
   "source": [
    "W = tf.zeros([1,4])\n",
    "\n",
    "b = tf.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = tf.transpose(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=2157740, shape=(4, 1), dtype=float32, numpy=\n",
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8a0wr94aTyjg"
   },
   "source": [
    "## Question 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zMXXYdOSxs0Q"
   },
   "source": [
    "### Get prediction\n",
    "- Define a function to get prediction\n",
    "- Approach: prediction = (X * W) + b; here is X is features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8Cty1y0xs0S"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#@tf.function\n",
    "def get_prediction(X, W, b):\n",
    "    prediction = np.dot(X,W) + b\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "in converted code:\n\n    <ipython-input-364-45873effdc6b>:4 get_prediction  *\n        prediction = np.dot(X,W) + b\n    <__array_function__ internals>:6 dot\n        \n    /Users/SaravanaTK/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:736 __array__\n        \" array.\".format(self.name))\n\n    NotImplementedError: Cannot convert a symbolic Tensor (W:0) to a numpy array.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-365-c093395a5549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    501\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m       \u001b[0minitializer_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_identity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mObjectIdentityDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    406\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    407\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 408\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2149\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2150\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2152\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2041\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    913\u001b[0m                                           converted_func)\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 358\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 905\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    906\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: in converted code:\n\n    <ipython-input-364-45873effdc6b>:4 get_prediction  *\n        prediction = np.dot(X,W) + b\n    <__array_function__ internals>:6 dot\n        \n    /Users/SaravanaTK/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:736 __array__\n        \" array.\".format(self.name))\n\n    NotImplementedError: Cannot convert a symbolic Tensor (W:0) to a numpy array.\n"
     ]
    }
   ],
   "source": [
    "print(get_prediction(X, W, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQmS3Tauxs0V"
   },
   "source": [
    "### Calculate loss\n",
    "- Calculate loss using predictions\n",
    "- Define a function to calculate loss\n",
    "- We are calculating mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-FRXmDd5xs0X"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZbBpnOtfT0wd"
   },
   "source": [
    "## Question 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bkOzAUUsTmF_"
   },
   "source": [
    "### Define a function to train the model\n",
    "1.   Record all the mathematical steps to calculate Loss\n",
    "2.   Calculate Gradients of Loss w.r.t weights and bias\n",
    "3.   Update Weights and Bias based on gradients and learning rate to minimize loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AW4SEP8kT2ls"
   },
   "source": [
    "## Question 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yeN0deOvT81N"
   },
   "source": [
    "### Train the model for 100 epochs \n",
    "- Observe the training loss at every iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jjkn4gUgLevE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "Loss at step 000: 237.287\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "Loss at step 020: 237.287\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "Loss at step 040: 237.287\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "Loss at step 060: 237.287\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "Loss at step 080: 237.287\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " ...\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]\n",
      " [ -2.1636  -2.3864  -2.4895 ... -37.1528  -6.5686  -5.6043]], shape=(1000, 1000), dtype=float32)\n",
      "tf.Tensor(237.28665, shape=(), dtype=float32)\n",
      "[None, None]\n",
      "W : [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]] , b  = [0.] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "#training info\n",
    "train_steps = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "for i in range(train_steps):\n",
    "  \n",
    "  #watch the gradient flow \n",
    "  with tf.GradientTape() as tape:\n",
    "    \n",
    "    #forward pass \n",
    "    yhat = get_prediction(X, W, b)\n",
    "    \n",
    "    #calcuate the loss (difference squared error)\n",
    "    #a_list = tf.unstack(yhat)\n",
    "    #for j in range(100):\n",
    "    #    a_list[j] = yhat[j,0:1] + yhat[j,1:2] + yhat[j,2:3] + yhat[j,3:4]\n",
    "    #yhat = tf.stack(a_list)\n",
    "    \n",
    "    #yhat = yhat[0, 3:4]\n",
    "    #print(yhat)\n",
    "    error = yhat - y\n",
    "    loss = tf.reduce_mean(tf.square(error))\n",
    "    print(error)\n",
    "    print(loss)\n",
    "  \n",
    "    #evalute the gradient with the respect to the paramters\n",
    "    gradients = tape.gradient(loss, [W, b])\n",
    "    print(gradients)\n",
    "    #print(db)\n",
    "    #update the paramters using Gradient Descent  \n",
    "    #W.assign_sub(dW * learning_rate)\n",
    "    #b.assign_sub(db * learning_rate)\n",
    "\n",
    "  #print the loss every 20 iterations \n",
    "  if i % 20 == 0:\n",
    "    print(\"Loss at step {:03d}: {:.3f}\".format(i, loss))\n",
    "      \n",
    "print(f'W : {W.numpy()} , b  = {b.numpy()} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vanvD93FV0_k"
   },
   "source": [
    "### Observe values of Weight\n",
    "- Print the updated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QSqpy4gtWaOD"
   },
   "outputs": [],
   "source": [
    "W.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y9KpRupYUEwy"
   },
   "source": [
    "### Observe values of Bias\n",
    "- Print the updated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bhEWkGqHWohg"
   },
   "outputs": [],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X[0,0]*W) + (X[0,1]*W) + (X[0,2]*W) + (X[0,3]*W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Questions - Internal - R6 - AIML Labs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
